{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from time import time\n",
    "\n",
    "from data_util import get_data_set, maybe_download_and_extract\n",
    "from model_util import model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name Fully connected layers/fc1 is illegal; using Fully_connected_layers/fc1 instead.\n",
      "INFO:tensorflow:Summary name Fully connected layers/fc1 is illegal; using Fully_connected_layers/fc1 instead.\n",
      "INFO:tensorflow:Summary name Fully connected layers/fc2 is illegal; using Fully_connected_layers/fc2 instead.\n",
      "INFO:tensorflow:Summary name Fully connected layers/fc2 is illegal; using Fully_connected_layers/fc2 instead.\n",
      "INFO:tensorflow:Summary name Fully connected layers/output is illegal; using Fully_connected_layers/output instead.\n"
     ]
    }
   ],
   "source": [
    "train_x, train_y, train_l = get_data_set(cifar=10)\n",
    "test_x, test_y, test_l = get_data_set(\"test\", cifar=10)\n",
    "\n",
    "x, y, output, global_step, y_pred_cls = model()\n",
    "\n",
    "_IMG_SIZE = 32\n",
    "_NUM_CHANNELS = 3\n",
    "_BATCH_SIZE = 128\n",
    "_CLASS_SIZE = 10\n",
    "_ITERATION = 1000\n",
    "_SAVE_PATH = \"/tmp/tensorboard/cifar-10/\"\n",
    "\n",
    "\n",
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=output, labels=y))\n",
    "optimizer = tf.train.RMSPropOptimizer(learning_rate=1e-4).minimize(loss, global_step=global_step)\n",
    "\n",
    "\n",
    "correct_prediction = tf.equal(y_pred_cls, tf.argmax(y, dimension=1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "tf.summary.scalar(\"Accuracy/train\", accuracy)\n",
    "\n",
    "\n",
    "merged = tf.summary.merge_all()\n",
    "saver = tf.train.Saver()\n",
    "sess = tf.Session()\n",
    "train_writer = tf.summary.FileWriter(_SAVE_PATH, sess.graph)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 3072)\n",
      "(50000, 10)\n",
      "['airplane', 'automobile', 'bird', 'cat', 'deer']\n"
     ]
    }
   ],
   "source": [
    "print(train_x.shape)\n",
    "print(train_y.shape)\n",
    "print(train_l[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(num_iterations):\n",
    "    '''\n",
    "        Train CNN\n",
    "    '''\n",
    "    for i in range(num_iterations):\n",
    "        randidx = np.random.randint(len(train_x), size=_BATCH_SIZE)\n",
    "        batch_xs = train_x[randidx]\n",
    "        batch_ys = train_y[randidx]\n",
    "\n",
    "        start_time = time()\n",
    "        i_global, _ = sess.run([global_step, optimizer], feed_dict={x: batch_xs, y: batch_ys})\n",
    "        duration = time() - start_time\n",
    "\n",
    "        if (i_global % 10 == 0) or (i == num_iterations - 1):\n",
    "            _loss, batch_acc = sess.run([loss, accuracy], feed_dict={x: batch_xs, y: batch_ys})\n",
    "            msg = \"Global Step: {0:>6}, accuracy: {1:>6.1%}, loss = {2:.2f} ({3:.1f} examples/sec, {4:.2f} sec/batch)\"\n",
    "            print(msg.format(i_global, batch_acc, _loss, _BATCH_SIZE / duration, duration))\n",
    "\n",
    "        if (i_global % 100 == 0) or (i == num_iterations - 1):\n",
    "            \n",
    "            \n",
    "            data_merged, global_1 = sess.run([merged, global_step], feed_dict={x: batch_xs, y: batch_ys})\n",
    "            acc = predict_test()\n",
    "\n",
    "            summary = tf.Summary(value=[\n",
    "                tf.Summary.Value(tag=\"Accuracy/test\", simple_value=acc),\n",
    "            ])\n",
    "            train_writer.add_summary(data_merged, global_1)\n",
    "            train_writer.add_summary(summary, global_1)\n",
    "\n",
    "            saver.save(sess, save_path=_SAVE_PATH, global_step=global_step)\n",
    "            print(\"Saved checkpoint.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict_test(show_confusion_matrix=False):\n",
    "    '''\n",
    "        Make prediction for all images in test_x\n",
    "    '''\n",
    "    i = 0\n",
    "    predicted_class = np.zeros(shape=len(test_x), dtype=np.int)\n",
    "    while i < len(test_x):\n",
    "        j = min(i + _BATCH_SIZE, len(test_x))\n",
    "        batch_xs = test_x[i:j, :]\n",
    "        batch_ys = test_y[i:j, :]\n",
    "        predicted_class[i:j] = sess.run(y_pred_cls, feed_dict={x: batch_xs, y: batch_ys})\n",
    "        i = j\n",
    "\n",
    "    correct = (np.argmax(test_y, axis=1) == predicted_class)\n",
    "    acc = correct.mean()*100\n",
    "    correct_numbers = correct.sum()\n",
    "    print(\"Accuracy on Test-Set: {0:.2f}% ({1} / {2})\".format(acc, correct_numbers, len(test_x)))\n",
    "\n",
    "    if show_confusion_matrix is True:\n",
    "        cm = confusion_matrix(y_true=np.argmax(test_y, axis=1), y_pred=predicted_class)\n",
    "        for i in range(_CLASS_SIZE):\n",
    "            class_name = \"({}) {}\".format(i, test_l[i])\n",
    "            print(cm[i, :], class_name)\n",
    "        class_numbers = [\" ({0})\".format(i) for i in range(_CLASS_SIZE)]\n",
    "        print(\"\".join(class_numbers))\n",
    "\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trying to restore last checkpoint ...\n",
      "INFO:tensorflow:Restoring parameters from None\n",
      "Failed to restore checkpoint. Initializing variables instead.\n",
      "Global Step:     10, accuracy:  12.5%, loss = 2.30 (620.8 examples/sec, 0.21 sec/batch)\n",
      "Global Step:     20, accuracy:   6.2%, loss = 2.31 (679.5 examples/sec, 0.19 sec/batch)\n",
      "Global Step:     30, accuracy:  10.9%, loss = 2.30 (885.3 examples/sec, 0.14 sec/batch)\n",
      "Global Step:     40, accuracy:  12.5%, loss = 2.30 (951.5 examples/sec, 0.13 sec/batch)\n",
      "Global Step:     50, accuracy:   9.4%, loss = 2.30 (916.9 examples/sec, 0.14 sec/batch)\n",
      "Global Step:     60, accuracy:   5.5%, loss = 2.30 (885.3 examples/sec, 0.14 sec/batch)\n",
      "Global Step:     70, accuracy:   9.4%, loss = 2.30 (972.4 examples/sec, 0.13 sec/batch)\n",
      "Global Step:     80, accuracy:  11.7%, loss = 2.30 (919.2 examples/sec, 0.14 sec/batch)\n",
      "Global Step:     90, accuracy:  12.5%, loss = 2.30 (884.6 examples/sec, 0.14 sec/batch)\n",
      "Global Step:    100, accuracy:  12.5%, loss = 2.30 (886.8 examples/sec, 0.14 sec/batch)\n",
      "Accuracy on Test-Set: 10.10% (1010 / 10000)\n",
      "Saved checkpoint.\n",
      "Global Step:    110, accuracy:  18.0%, loss = 2.30 (930.7 examples/sec, 0.14 sec/batch)\n",
      "Global Step:    120, accuracy:  13.3%, loss = 2.30 (889.6 examples/sec, 0.14 sec/batch)\n",
      "Global Step:    130, accuracy:  10.2%, loss = 2.30 (901.3 examples/sec, 0.14 sec/batch)\n",
      "Global Step:    140, accuracy:  14.1%, loss = 2.29 (931.8 examples/sec, 0.14 sec/batch)\n",
      "Global Step:    150, accuracy:  13.3%, loss = 2.29 (913.3 examples/sec, 0.14 sec/batch)\n",
      "Global Step:    160, accuracy:  11.7%, loss = 2.28 (929.3 examples/sec, 0.14 sec/batch)\n",
      "Global Step:    170, accuracy:  15.6%, loss = 2.26 (936.9 examples/sec, 0.14 sec/batch)\n",
      "Global Step:    180, accuracy:  11.7%, loss = 2.23 (981.8 examples/sec, 0.13 sec/batch)\n",
      "Global Step:    190, accuracy:  13.3%, loss = 2.22 (910.1 examples/sec, 0.14 sec/batch)\n",
      "Global Step:    200, accuracy:  14.1%, loss = 2.23 (927.7 examples/sec, 0.14 sec/batch)\n",
      "Accuracy on Test-Set: 13.52% (1352 / 10000)\n",
      "Saved checkpoint.\n",
      "Global Step:    210, accuracy:  21.9%, loss = 2.06 (931.9 examples/sec, 0.14 sec/batch)\n",
      "Global Step:    220, accuracy:  21.9%, loss = 2.04 (928.9 examples/sec, 0.14 sec/batch)\n",
      "Global Step:    230, accuracy:  28.9%, loss = 2.04 (862.5 examples/sec, 0.15 sec/batch)\n",
      "Global Step:    240, accuracy:  24.2%, loss = 2.08 (884.5 examples/sec, 0.14 sec/batch)\n",
      "Global Step:    250, accuracy:  26.6%, loss = 2.09 (884.5 examples/sec, 0.14 sec/batch)\n",
      "Global Step:    260, accuracy:  28.1%, loss = 1.98 (915.5 examples/sec, 0.14 sec/batch)\n",
      "Global Step:    270, accuracy:  28.1%, loss = 2.03 (914.4 examples/sec, 0.14 sec/batch)\n",
      "Global Step:    280, accuracy:  23.4%, loss = 2.06 (1012.6 examples/sec, 0.13 sec/batch)\n",
      "Global Step:    290, accuracy:  28.9%, loss = 2.04 (930.1 examples/sec, 0.14 sec/batch)\n",
      "Global Step:    300, accuracy:  29.7%, loss = 1.94 (866.3 examples/sec, 0.15 sec/batch)\n",
      "Accuracy on Test-Set: 26.16% (2616 / 10000)\n",
      "Saved checkpoint.\n",
      "Global Step:    310, accuracy:  25.8%, loss = 2.07 (1022.1 examples/sec, 0.13 sec/batch)\n",
      "Global Step:    320, accuracy:  24.2%, loss = 1.90 (929.3 examples/sec, 0.14 sec/batch)\n",
      "Global Step:    330, accuracy:  33.6%, loss = 1.91 (928.9 examples/sec, 0.14 sec/batch)\n",
      "Global Step:    340, accuracy:  31.2%, loss = 1.95 (931.8 examples/sec, 0.14 sec/batch)\n",
      "Global Step:    350, accuracy:  28.9%, loss = 1.92 (925.1 examples/sec, 0.14 sec/batch)\n",
      "Global Step:    360, accuracy:  31.2%, loss = 1.85 (972.6 examples/sec, 0.13 sec/batch)\n",
      "Global Step:    370, accuracy:  29.7%, loss = 1.80 (926.6 examples/sec, 0.14 sec/batch)\n",
      "Global Step:    380, accuracy:  30.5%, loss = 1.81 (886.6 examples/sec, 0.14 sec/batch)\n",
      "Global Step:    390, accuracy:  31.2%, loss = 1.86 (902.5 examples/sec, 0.14 sec/batch)\n",
      "Global Step:    400, accuracy:  31.2%, loss = 1.82 (931.2 examples/sec, 0.14 sec/batch)\n",
      "Accuracy on Test-Set: 31.68% (3168 / 10000)\n",
      "Saved checkpoint.\n",
      "Global Step:    410, accuracy:  33.6%, loss = 1.89 (942.8 examples/sec, 0.14 sec/batch)\n",
      "Global Step:    420, accuracy:  33.6%, loss = 1.89 (930.6 examples/sec, 0.14 sec/batch)\n",
      "Global Step:    430, accuracy:  35.9%, loss = 1.82 (879.9 examples/sec, 0.15 sec/batch)\n",
      "Global Step:    440, accuracy:  23.4%, loss = 1.87 (926.3 examples/sec, 0.14 sec/batch)\n",
      "Global Step:    450, accuracy:  38.3%, loss = 1.84 (925.7 examples/sec, 0.14 sec/batch)\n",
      "Global Step:    460, accuracy:  33.6%, loss = 1.90 (956.4 examples/sec, 0.13 sec/batch)\n",
      "Global Step:    470, accuracy:  37.5%, loss = 1.72 (898.1 examples/sec, 0.14 sec/batch)\n",
      "Global Step:    480, accuracy:  39.1%, loss = 1.81 (877.9 examples/sec, 0.15 sec/batch)\n",
      "Global Step:    490, accuracy:  36.7%, loss = 1.81 (923.1 examples/sec, 0.14 sec/batch)\n",
      "Global Step:    500, accuracy:  40.6%, loss = 1.79 (926.8 examples/sec, 0.14 sec/batch)\n",
      "Accuracy on Test-Set: 32.47% (3247 / 10000)\n",
      "Saved checkpoint.\n",
      "Global Step:    510, accuracy:  31.2%, loss = 1.84 (897.3 examples/sec, 0.14 sec/batch)\n",
      "Global Step:    520, accuracy:  38.3%, loss = 1.69 (918.4 examples/sec, 0.14 sec/batch)\n",
      "Global Step:    530, accuracy:  26.6%, loss = 1.87 (899.0 examples/sec, 0.14 sec/batch)\n",
      "Global Step:    540, accuracy:  32.8%, loss = 1.84 (920.6 examples/sec, 0.14 sec/batch)\n",
      "Global Step:    550, accuracy:  38.3%, loss = 1.68 (922.2 examples/sec, 0.14 sec/batch)\n",
      "Global Step:    560, accuracy:  42.2%, loss = 1.66 (948.0 examples/sec, 0.14 sec/batch)\n",
      "Global Step:    570, accuracy:  38.3%, loss = 1.80 (904.1 examples/sec, 0.14 sec/batch)\n",
      "Global Step:    580, accuracy:  39.1%, loss = 1.65 (971.8 examples/sec, 0.13 sec/batch)\n",
      "Global Step:    590, accuracy:  41.4%, loss = 1.71 (919.9 examples/sec, 0.14 sec/batch)\n",
      "Global Step:    600, accuracy:  43.0%, loss = 1.74 (886.5 examples/sec, 0.14 sec/batch)\n",
      "Accuracy on Test-Set: 36.60% (3660 / 10000)\n",
      "Saved checkpoint.\n",
      "Global Step:    610, accuracy:  39.1%, loss = 1.71 (927.5 examples/sec, 0.14 sec/batch)\n",
      "Global Step:    620, accuracy:  41.4%, loss = 1.68 (909.3 examples/sec, 0.14 sec/batch)\n",
      "Global Step:    630, accuracy:  43.0%, loss = 1.64 (925.7 examples/sec, 0.14 sec/batch)\n",
      "Global Step:    640, accuracy:  39.8%, loss = 1.61 (938.1 examples/sec, 0.14 sec/batch)\n",
      "Global Step:    650, accuracy:  39.1%, loss = 1.68 (929.1 examples/sec, 0.14 sec/batch)\n",
      "Global Step:    660, accuracy:  40.6%, loss = 1.53 (1002.5 examples/sec, 0.13 sec/batch)\n",
      "Global Step:    670, accuracy:  38.3%, loss = 1.69 (928.6 examples/sec, 0.14 sec/batch)\n",
      "Global Step:    680, accuracy:  37.5%, loss = 1.62 (943.9 examples/sec, 0.14 sec/batch)\n",
      "Global Step:    690, accuracy:  30.5%, loss = 1.81 (905.4 examples/sec, 0.14 sec/batch)\n",
      "Global Step:    700, accuracy:  35.2%, loss = 1.70 (929.6 examples/sec, 0.14 sec/batch)\n",
      "Accuracy on Test-Set: 37.51% (3751 / 10000)\n",
      "Saved checkpoint.\n",
      "Global Step:    710, accuracy:  41.4%, loss = 1.53 (925.7 examples/sec, 0.14 sec/batch)\n",
      "Global Step:    720, accuracy:  46.1%, loss = 1.45 (918.1 examples/sec, 0.14 sec/batch)\n",
      "Global Step:    730, accuracy:  38.3%, loss = 1.65 (939.2 examples/sec, 0.14 sec/batch)\n",
      "Global Step:    740, accuracy:  41.4%, loss = 1.65 (937.7 examples/sec, 0.14 sec/batch)\n",
      "Global Step:    750, accuracy:  42.2%, loss = 1.50 (882.1 examples/sec, 0.15 sec/batch)\n",
      "Global Step:    760, accuracy:  43.0%, loss = 1.73 (903.2 examples/sec, 0.14 sec/batch)\n",
      "Global Step:    770, accuracy:  40.6%, loss = 1.52 (930.6 examples/sec, 0.14 sec/batch)\n",
      "Global Step:    780, accuracy:  37.5%, loss = 1.60 (894.8 examples/sec, 0.14 sec/batch)\n",
      "Global Step:    790, accuracy:  36.7%, loss = 1.68 (907.4 examples/sec, 0.14 sec/batch)\n",
      "Global Step:    800, accuracy:  43.0%, loss = 1.56 (936.1 examples/sec, 0.14 sec/batch)\n",
      "Accuracy on Test-Set: 40.45% (4045 / 10000)\n",
      "Saved checkpoint.\n",
      "Global Step:    810, accuracy:  53.9%, loss = 1.43 (928.7 examples/sec, 0.14 sec/batch)\n",
      "Global Step:    820, accuracy:  32.8%, loss = 1.79 (927.5 examples/sec, 0.14 sec/batch)\n",
      "Global Step:    830, accuracy:  45.3%, loss = 1.52 (967.2 examples/sec, 0.13 sec/batch)\n",
      "Global Step:    840, accuracy:  38.3%, loss = 1.64 (945.4 examples/sec, 0.14 sec/batch)\n",
      "Global Step:    850, accuracy:  36.7%, loss = 1.57 (929.5 examples/sec, 0.14 sec/batch)\n",
      "Global Step:    860, accuracy:  46.9%, loss = 1.47 (1026.0 examples/sec, 0.12 sec/batch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global Step:    870, accuracy:  40.6%, loss = 1.46 (948.0 examples/sec, 0.14 sec/batch)\n",
      "Global Step:    880, accuracy:  45.3%, loss = 1.58 (927.9 examples/sec, 0.14 sec/batch)\n",
      "Global Step:    890, accuracy:  42.2%, loss = 1.54 (890.8 examples/sec, 0.14 sec/batch)\n",
      "Global Step:    900, accuracy:  39.8%, loss = 1.55 (868.8 examples/sec, 0.15 sec/batch)\n",
      "Accuracy on Test-Set: 40.53% (4053 / 10000)\n",
      "Saved checkpoint.\n",
      "Global Step:    910, accuracy:  39.1%, loss = 1.77 (931.7 examples/sec, 0.14 sec/batch)\n",
      "Global Step:    920, accuracy:  46.1%, loss = 1.48 (972.3 examples/sec, 0.13 sec/batch)\n",
      "Global Step:    930, accuracy:  35.9%, loss = 1.58 (919.6 examples/sec, 0.14 sec/batch)\n",
      "Global Step:    940, accuracy:  46.9%, loss = 1.50 (966.5 examples/sec, 0.13 sec/batch)\n",
      "Global Step:    950, accuracy:  45.3%, loss = 1.45 (928.0 examples/sec, 0.14 sec/batch)\n",
      "Global Step:    960, accuracy:  44.5%, loss = 1.48 (898.3 examples/sec, 0.14 sec/batch)\n",
      "Global Step:    970, accuracy:  44.5%, loss = 1.57 (967.8 examples/sec, 0.13 sec/batch)\n",
      "Global Step:    980, accuracy:  43.8%, loss = 1.53 (925.7 examples/sec, 0.14 sec/batch)\n",
      "Global Step:    990, accuracy:  48.4%, loss = 1.37 (927.1 examples/sec, 0.14 sec/batch)\n",
      "Global Step:   1000, accuracy:  43.0%, loss = 1.50 (928.4 examples/sec, 0.14 sec/batch)\n",
      "Accuracy on Test-Set: 41.00% (4100 / 10000)\n",
      "Saved checkpoint.\n",
      "Global Step:   1010, accuracy:  41.4%, loss = 1.57 (926.2 examples/sec, 0.14 sec/batch)\n",
      "Global Step:   1020, accuracy:  46.1%, loss = 1.48 (926.7 examples/sec, 0.14 sec/batch)\n",
      "Global Step:   1030, accuracy:  44.5%, loss = 1.45 (930.6 examples/sec, 0.14 sec/batch)\n",
      "Global Step:   1040, accuracy:  46.1%, loss = 1.43 (973.9 examples/sec, 0.13 sec/batch)\n",
      "Global Step:   1050, accuracy:  45.3%, loss = 1.42 (941.8 examples/sec, 0.14 sec/batch)\n",
      "Global Step:   1060, accuracy:  46.9%, loss = 1.51 (920.0 examples/sec, 0.14 sec/batch)\n",
      "Global Step:   1070, accuracy:  49.2%, loss = 1.52 (927.3 examples/sec, 0.14 sec/batch)\n",
      "Global Step:   1080, accuracy:  51.6%, loss = 1.44 (920.8 examples/sec, 0.14 sec/batch)\n",
      "Global Step:   1090, accuracy:  50.0%, loss = 1.29 (926.1 examples/sec, 0.14 sec/batch)\n",
      "Global Step:   1100, accuracy:  45.3%, loss = 1.47 (963.2 examples/sec, 0.13 sec/batch)\n",
      "Accuracy on Test-Set: 45.05% (4505 / 10000)\n",
      "Saved checkpoint.\n",
      "Global Step:   1110, accuracy:  48.4%, loss = 1.45 (965.4 examples/sec, 0.13 sec/batch)\n",
      "Global Step:   1120, accuracy:  46.9%, loss = 1.45 (964.9 examples/sec, 0.13 sec/batch)\n",
      "Global Step:   1130, accuracy:  46.9%, loss = 1.53 (961.3 examples/sec, 0.13 sec/batch)\n",
      "Global Step:   1140, accuracy:  50.8%, loss = 1.33 (927.2 examples/sec, 0.14 sec/batch)\n",
      "Global Step:   1150, accuracy:  45.3%, loss = 1.40 (924.1 examples/sec, 0.14 sec/batch)\n",
      "Global Step:   1160, accuracy:  50.8%, loss = 1.46 (893.8 examples/sec, 0.14 sec/batch)\n",
      "Global Step:   1170, accuracy:  50.8%, loss = 1.31 (923.5 examples/sec, 0.14 sec/batch)\n",
      "Global Step:   1180, accuracy:  47.7%, loss = 1.39 (924.6 examples/sec, 0.14 sec/batch)\n",
      "Global Step:   1190, accuracy:  48.4%, loss = 1.39 (969.0 examples/sec, 0.13 sec/batch)\n",
      "Global Step:   1200, accuracy:  53.1%, loss = 1.34 (870.1 examples/sec, 0.15 sec/batch)\n",
      "Accuracy on Test-Set: 45.44% (4544 / 10000)\n",
      "Saved checkpoint.\n",
      "Global Step:   1210, accuracy:  50.0%, loss = 1.36 (929.5 examples/sec, 0.14 sec/batch)\n",
      "Global Step:   1220, accuracy:  46.1%, loss = 1.47 (909.5 examples/sec, 0.14 sec/batch)\n",
      "Global Step:   1230, accuracy:  43.0%, loss = 1.50 (967.0 examples/sec, 0.13 sec/batch)\n",
      "Global Step:   1240, accuracy:  46.1%, loss = 1.43 (899.9 examples/sec, 0.14 sec/batch)\n",
      "Global Step:   1250, accuracy:  47.7%, loss = 1.41 (926.3 examples/sec, 0.14 sec/batch)\n",
      "Global Step:   1260, accuracy:  37.5%, loss = 1.58 (970.6 examples/sec, 0.13 sec/batch)\n",
      "Global Step:   1270, accuracy:  50.8%, loss = 1.33 (930.3 examples/sec, 0.14 sec/batch)\n",
      "Global Step:   1280, accuracy:  52.3%, loss = 1.36 (858.2 examples/sec, 0.15 sec/batch)\n",
      "Global Step:   1290, accuracy:  49.2%, loss = 1.39 (884.3 examples/sec, 0.14 sec/batch)\n",
      "Global Step:   1300, accuracy:  50.0%, loss = 1.37 (931.2 examples/sec, 0.14 sec/batch)\n",
      "Accuracy on Test-Set: 47.72% (4772 / 10000)\n",
      "Saved checkpoint.\n",
      "Global Step:   1310, accuracy:  44.5%, loss = 1.38 (836.5 examples/sec, 0.15 sec/batch)\n",
      "Global Step:   1320, accuracy:  52.3%, loss = 1.32 (899.3 examples/sec, 0.14 sec/batch)\n",
      "Global Step:   1330, accuracy:  53.9%, loss = 1.35 (902.9 examples/sec, 0.14 sec/batch)\n",
      "Global Step:   1340, accuracy:  50.8%, loss = 1.34 (928.3 examples/sec, 0.14 sec/batch)\n",
      "Global Step:   1350, accuracy:  51.6%, loss = 1.45 (929.8 examples/sec, 0.14 sec/batch)\n",
      "Global Step:   1360, accuracy:  43.8%, loss = 1.42 (884.6 examples/sec, 0.14 sec/batch)\n",
      "Global Step:   1370, accuracy:  52.3%, loss = 1.34 (906.9 examples/sec, 0.14 sec/batch)\n",
      "Global Step:   1380, accuracy:  51.6%, loss = 1.44 (946.4 examples/sec, 0.14 sec/batch)\n",
      "Global Step:   1390, accuracy:  48.4%, loss = 1.38 (901.6 examples/sec, 0.14 sec/batch)\n",
      "Global Step:   1400, accuracy:  52.3%, loss = 1.25 (915.5 examples/sec, 0.14 sec/batch)\n",
      "Accuracy on Test-Set: 48.50% (4850 / 10000)\n",
      "Saved checkpoint.\n",
      "Global Step:   1410, accuracy:  52.3%, loss = 1.26 (905.0 examples/sec, 0.14 sec/batch)\n",
      "Global Step:   1420, accuracy:  47.7%, loss = 1.50 (908.9 examples/sec, 0.14 sec/batch)\n",
      "Global Step:   1430, accuracy:  47.7%, loss = 1.44 (979.9 examples/sec, 0.13 sec/batch)\n",
      "Global Step:   1440, accuracy:  50.0%, loss = 1.27 (925.5 examples/sec, 0.14 sec/batch)\n",
      "Global Step:   1450, accuracy:  42.2%, loss = 1.38 (919.6 examples/sec, 0.14 sec/batch)\n",
      "Global Step:   1460, accuracy:  44.5%, loss = 1.46 (976.2 examples/sec, 0.13 sec/batch)\n",
      "Global Step:   1470, accuracy:  53.9%, loss = 1.24 (926.4 examples/sec, 0.14 sec/batch)\n",
      "Global Step:   1480, accuracy:  47.7%, loss = 1.30 (981.6 examples/sec, 0.13 sec/batch)\n",
      "Global Step:   1490, accuracy:  46.9%, loss = 1.49 (903.8 examples/sec, 0.14 sec/batch)\n",
      "Global Step:   1500, accuracy:  53.1%, loss = 1.35 (928.5 examples/sec, 0.14 sec/batch)\n",
      "Accuracy on Test-Set: 49.18% (4918 / 10000)\n",
      "Saved checkpoint.\n",
      "Global Step:   1510, accuracy:  44.5%, loss = 1.34 (926.3 examples/sec, 0.14 sec/batch)\n",
      "Global Step:   1520, accuracy:  46.1%, loss = 1.41 (934.6 examples/sec, 0.14 sec/batch)\n",
      "Global Step:   1530, accuracy:  53.9%, loss = 1.36 (907.0 examples/sec, 0.14 sec/batch)\n",
      "Global Step:   1540, accuracy:  49.2%, loss = 1.30 (978.9 examples/sec, 0.13 sec/batch)\n",
      "Global Step:   1550, accuracy:  52.3%, loss = 1.33 (932.9 examples/sec, 0.14 sec/batch)\n",
      "Global Step:   1560, accuracy:  45.3%, loss = 1.44 (928.6 examples/sec, 0.14 sec/batch)\n",
      "Global Step:   1570, accuracy:  55.5%, loss = 1.32 (931.6 examples/sec, 0.14 sec/batch)\n",
      "Global Step:   1580, accuracy:  53.1%, loss = 1.27 (927.0 examples/sec, 0.14 sec/batch)\n",
      "Global Step:   1590, accuracy:  50.0%, loss = 1.27 (930.4 examples/sec, 0.14 sec/batch)\n",
      "Global Step:   1600, accuracy:  46.1%, loss = 1.36 (966.4 examples/sec, 0.13 sec/batch)\n",
      "Accuracy on Test-Set: 47.01% (4701 / 10000)\n",
      "Saved checkpoint.\n",
      "Global Step:   1610, accuracy:  53.9%, loss = 1.27 (893.2 examples/sec, 0.14 sec/batch)\n",
      "Global Step:   1620, accuracy:  55.5%, loss = 1.31 (929.0 examples/sec, 0.14 sec/batch)\n",
      "Global Step:   1630, accuracy:  49.2%, loss = 1.28 (928.1 examples/sec, 0.14 sec/batch)\n",
      "Global Step:   1640, accuracy:  48.4%, loss = 1.31 (895.4 examples/sec, 0.14 sec/batch)\n",
      "Global Step:   1650, accuracy:  48.4%, loss = 1.45 (930.7 examples/sec, 0.14 sec/batch)\n",
      "Global Step:   1660, accuracy:  46.1%, loss = 1.43 (920.8 examples/sec, 0.14 sec/batch)\n",
      "Global Step:   1670, accuracy:  53.9%, loss = 1.24 (929.5 examples/sec, 0.14 sec/batch)\n",
      "Global Step:   1680, accuracy:  54.7%, loss = 1.29 (885.7 examples/sec, 0.14 sec/batch)\n",
      "Global Step:   1690, accuracy:  46.1%, loss = 1.46 (901.3 examples/sec, 0.14 sec/batch)\n",
      "Global Step:   1700, accuracy:  53.1%, loss = 1.26 (917.7 examples/sec, 0.14 sec/batch)\n",
      "Accuracy on Test-Set: 51.98% (5198 / 10000)\n",
      "Saved checkpoint.\n",
      "Global Step:   1710, accuracy:  57.8%, loss = 1.27 (940.2 examples/sec, 0.14 sec/batch)\n",
      "Global Step:   1720, accuracy:  57.0%, loss = 1.22 (926.5 examples/sec, 0.14 sec/batch)\n",
      "Global Step:   1730, accuracy:  48.4%, loss = 1.29 (885.0 examples/sec, 0.14 sec/batch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global Step:   1740, accuracy:  56.2%, loss = 1.16 (932.4 examples/sec, 0.14 sec/batch)\n",
      "Global Step:   1750, accuracy:  44.5%, loss = 1.42 (935.4 examples/sec, 0.14 sec/batch)\n",
      "Global Step:   1760, accuracy:  50.0%, loss = 1.41 (924.2 examples/sec, 0.14 sec/batch)\n",
      "Global Step:   1770, accuracy:  50.8%, loss = 1.27 (946.8 examples/sec, 0.14 sec/batch)\n",
      "Global Step:   1780, accuracy:  49.2%, loss = 1.36 (930.1 examples/sec, 0.14 sec/batch)\n",
      "Global Step:   1790, accuracy:  63.3%, loss = 1.12 (881.1 examples/sec, 0.15 sec/batch)\n",
      "Global Step:   1800, accuracy:  50.8%, loss = 1.32 (964.9 examples/sec, 0.13 sec/batch)\n",
      "Accuracy on Test-Set: 50.24% (5024 / 10000)\n",
      "Saved checkpoint.\n",
      "Global Step:   1810, accuracy:  58.6%, loss = 1.17 (926.4 examples/sec, 0.14 sec/batch)\n",
      "Global Step:   1820, accuracy:  57.8%, loss = 1.21 (931.3 examples/sec, 0.14 sec/batch)\n",
      "Global Step:   1830, accuracy:  51.6%, loss = 1.33 (1011.3 examples/sec, 0.13 sec/batch)\n",
      "Global Step:   1840, accuracy:  53.1%, loss = 1.20 (939.7 examples/sec, 0.14 sec/batch)\n",
      "Global Step:   1850, accuracy:  54.7%, loss = 1.23 (945.8 examples/sec, 0.14 sec/batch)\n",
      "Global Step:   1860, accuracy:  48.4%, loss = 1.27 (927.3 examples/sec, 0.14 sec/batch)\n",
      "Global Step:   1870, accuracy:  53.1%, loss = 1.20 (975.0 examples/sec, 0.13 sec/batch)\n",
      "Global Step:   1880, accuracy:  57.0%, loss = 1.23 (930.2 examples/sec, 0.14 sec/batch)\n",
      "Global Step:   1890, accuracy:  65.6%, loss = 1.03 (879.1 examples/sec, 0.15 sec/batch)\n",
      "Global Step:   1900, accuracy:  59.4%, loss = 1.11 (923.7 examples/sec, 0.14 sec/batch)\n",
      "Accuracy on Test-Set: 54.09% (5409 / 10000)\n",
      "Saved checkpoint.\n",
      "Global Step:   1910, accuracy:  50.8%, loss = 1.22 (921.5 examples/sec, 0.14 sec/batch)\n",
      "Global Step:   1920, accuracy:  56.2%, loss = 1.25 (882.4 examples/sec, 0.15 sec/batch)\n",
      "Global Step:   1930, accuracy:  54.7%, loss = 1.19 (925.0 examples/sec, 0.14 sec/batch)\n",
      "Global Step:   1940, accuracy:  57.8%, loss = 1.13 (922.2 examples/sec, 0.14 sec/batch)\n",
      "Global Step:   1950, accuracy:  57.8%, loss = 1.19 (851.4 examples/sec, 0.15 sec/batch)\n",
      "Global Step:   1960, accuracy:  59.4%, loss = 1.17 (869.6 examples/sec, 0.15 sec/batch)\n",
      "Global Step:   1970, accuracy:  55.5%, loss = 1.30 (928.0 examples/sec, 0.14 sec/batch)\n",
      "Global Step:   1980, accuracy:  57.0%, loss = 1.23 (954.8 examples/sec, 0.13 sec/batch)\n",
      "Global Step:   1990, accuracy:  46.9%, loss = 1.35 (846.4 examples/sec, 0.15 sec/batch)\n",
      "Global Step:   2000, accuracy:  62.5%, loss = 1.14 (931.2 examples/sec, 0.14 sec/batch)\n",
      "Accuracy on Test-Set: 53.71% (5371 / 10000)\n",
      "Saved checkpoint.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "try:\n",
    "    print(\"Trying to restore last checkpoint ...\")\n",
    "    last_chk_path = tf.train.latest_checkpoint(checkpoint_dir=_SAVE_PATH)\n",
    "    saver.restore(sess, save_path=last_chk_path)\n",
    "    print(\"Restored checkpoint from:\", last_chk_path)\n",
    "except:\n",
    "    print(\"Failed to restore checkpoint. Initializing variables instead.\")\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "if _ITERATION != 0:\n",
    "    train(_ITERATION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on Test-Set: 53.71% (5371 / 10000)\n",
      "[571  52  46  21   4   7  12   7 222  58] (0) airplane\n",
      "[ 18 742   2  12   1   2   9   4  63 147] (1) automobile\n",
      "[ 98  26 354 142  67 110  81  46  46  30] (2) bird\n",
      "[ 32  25  88 470  15 201  55  22  37  55] (3) cat\n",
      "[ 56  11 183 117 230  99 135 114  39  16] (4) deer\n",
      "[ 21  11  89 268  14 469  23  55  25  25] (5) dog\n",
      "[ 10  21  61 180  25  20 613   5  20  45] (6) frog\n",
      "[ 31  13  44  86  46 132  19 536  17  76] (7) horse\n",
      "[ 73  73  13  12   0   6   5   3 769  46] (8) ship\n",
      "[ 22 217  10  24   1   5  12   9  83 617] (9) truck\n",
      " (0) (1) (2) (3) (4) (5) (6) (7) (8) (9)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "53.710000000000001"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_test(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3, 3072), (3, 10))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g = tf.get_default_graph()\n",
    "feed = g.get_tensor_by_name('data/Input:0')\n",
    "fetch = g.get_tensor_by_name('output/output:0')\n",
    "\n",
    "# Feeding 3 images through the net just for testing\n",
    "feed_vals = train_x[0:3]\n",
    "res = sess.run(fetch, feed_dict={feed:feed_vals})\n",
    "np.shape(feed_vals), res.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5000\n",
      "10000\n",
      "15000\n",
      "20000\n",
      "25000\n",
      "30000\n",
      "35000\n",
      "40000\n",
      "45000\n"
     ]
    }
   ],
   "source": [
    "# for embedding\n",
    "N = 50000\n",
    "p = 10\n",
    "EMB = np.zeros((N, p), dtype='float32')\n",
    "for i in range(N): #Of course you could do mini-batches\n",
    "    EMB[i] = sess.run(fetch, feed_dict={feed: train_x[i:i+1,:]})\n",
    "    if (i % 5000 == 0 or i < 5):\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/tmp/tensorboard/cifar-10/model2.ckpt-1'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LOG_DIR = _SAVE_PATH\n",
    "from tensorflow.contrib.tensorboard.plugins import projector\n",
    "import os\n",
    "# The embedding variable, which needs to be stored\n",
    "# Note this must a Variable not a Tensor!\n",
    "embedding_var = tf.Variable(EMB,  name='Embedding_of_output')\n",
    "sess.run(embedding_var.initializer)\n",
    "summary_writer = tf.summary.FileWriter(LOG_DIR)\n",
    "config = projector.ProjectorConfig()\n",
    "embedding = config.embeddings.add()\n",
    "embedding.tensor_name = embedding_var.name\n",
    "\n",
    "# Comment out if you don't have metadata\n",
    "embedding.metadata_path = os.path.join(LOG_DIR, 'metadata.tsv')\n",
    "\n",
    "projector.visualize_embeddings(summary_writer, config)\n",
    "saver = tf.train.Saver([embedding_var])\n",
    "saver.save(sess, os.path.join(LOG_DIR, 'model2.ckpt'), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.]\n",
      " [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.]\n",
      " [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.]]\n",
      "['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
      "frog\n",
      "truck\n",
      "truck\n"
     ]
    }
   ],
   "source": [
    "metadata_file = open(os.path.join(LOG_DIR, 'metadata.tsv'), 'w')\n",
    "metadata_file.write('Name\\tClass\\n')\n",
    "print(train_y[:5])\n",
    "print(train_l)\n",
    "\n",
    "print(train_l[np.argmax(train_y[0])])\n",
    "print(train_l[np.argmax(train_y[1])])\n",
    "print(train_l[np.argmax(train_y[2])])\n",
    "\n",
    "for i in range(N):\n",
    "    metadata_file.write('%06d\\t%s\\n' % (i, train_l[np.argmax(train_y[i])]))\n",
    "metadata_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 99M\r\n",
      "-rw-rw-r-- 1 jac jac  16M Sep 18 18:00 -1600.data-00000-of-00001\r\n",
      "-rw-rw-r-- 1 jac jac 1.9K Sep 18 18:00 -1600.index\r\n",
      "-rw-rw-r-- 1 jac jac 150K Sep 18 18:00 -1600.meta\r\n",
      "-rw-rw-r-- 1 jac jac  16M Sep 18 18:01 -1700.data-00000-of-00001\r\n",
      "-rw-rw-r-- 1 jac jac 1.9K Sep 18 18:01 -1700.index\r\n",
      "-rw-rw-r-- 1 jac jac 150K Sep 18 18:01 -1700.meta\r\n",
      "-rw-rw-r-- 1 jac jac  16M Sep 18 18:01 -1800.data-00000-of-00001\r\n",
      "-rw-rw-r-- 1 jac jac 1.9K Sep 18 18:01 -1800.index\r\n",
      "-rw-rw-r-- 1 jac jac 150K Sep 18 18:01 -1800.meta\r\n",
      "-rw-rw-r-- 1 jac jac  16M Sep 18 18:01 -1900.data-00000-of-00001\r\n",
      "-rw-rw-r-- 1 jac jac 1.9K Sep 18 18:01 -1900.index\r\n",
      "-rw-rw-r-- 1 jac jac 150K Sep 18 18:01 -1900.meta\r\n",
      "-rw-rw-r-- 1 jac jac  16M Sep 18 18:01 -2000.data-00000-of-00001\r\n",
      "-rw-rw-r-- 1 jac jac 1.9K Sep 18 18:01 -2000.index\r\n",
      "-rw-rw-r-- 1 jac jac 150K Sep 18 18:01 -2000.meta\r\n",
      "-rw-rw-r-- 1 jac jac  135 Sep 18 18:28 checkpoint\r\n",
      "-rw-rw-r-- 1 jac jac 767K Sep 18 18:01 events.out.tfevents.1505728544.jac-T5-SKYLAKE\r\n",
      "-rw-rw-r-- 1 jac jac 635K Sep 18 18:28 metadata.tsv\r\n",
      "-rw-rw-r-- 1 jac jac 2.0M Sep 18 18:28 model2.ckpt-1.data-00000-of-00001\r\n",
      "-rw-rw-r-- 1 jac jac  149 Sep 18 18:28 model2.ckpt-1.index\r\n",
      "-rw-rw-r-- 1 jac jac 9.7M Sep 18 18:28 model2.ckpt-1.meta\r\n",
      "-rw-rw-r-- 1 jac jac 2.0M Sep 18 18:17 model666.ckpt-1.data-00000-of-00001\r\n",
      "-rw-rw-r-- 1 jac jac  149 Sep 18 18:17 model666.ckpt-1.index\r\n",
      "-rw-rw-r-- 1 jac jac 5.9M Sep 18 18:17 model666.ckpt-1.meta\r\n",
      "-rw-rw-r-- 1 jac jac  114 Sep 18 18:28 projector_config.pbtxt\r\n"
     ]
    }
   ],
   "source": [
    "%ls -lhl /tmp/tensorboard/cifar-10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
